{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN36nLGETOI0oN52ulkrl45",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/calyaconsult/juypter-notebooks/blob/main/File_Archive_Clusters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tP29ONny5d5",
        "outputId": "4e4fffee-a212-4303-d2f4-1bc4b22c4cd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKg3V3v_iQEA"
      },
      "outputs": [],
      "source": [
        "# Define the file path in your Google Drive\n",
        "file_path = '/content/drive/My Drive/Data/unique_filenames.txt'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Install rapidfuzz first if needed:\n",
        "# !pip install rapidfuzz\n",
        "from rapidfuzz import fuzz\n",
        "\n",
        "# --- Configuration ---\n",
        "SIMILARITY_THRESHOLD = 85   # adjust as needed\n",
        "MIN_CLUSTER_SIZE = 5        # only print clusters with >=5 files\n",
        "SKIP_EXTENSIONS = {'.pdf', '.jpg', '.jpeg', '.png', '.gif', '.bmp', '.svg', '.webp', '.ico'}\n",
        "# Skip certain filename patterns\n",
        "SKIP_PATTERNS = [\"lorem-\",\"ipsum\"]  # anything containing this substring will be ignored"
      ],
      "metadata": {
        "id": "98HZhHnhm6AT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Helper function: Longest Common Substring ---\n",
        "def longest_common_substring(a, b):\n",
        "    m, n = len(a), len(b)\n",
        "    dp = [[0]*(n+1) for _ in range(m+1)]\n",
        "    length, end = 0, 0\n",
        "    for i in range(1, m+1):\n",
        "        for j in range(1, n+1):\n",
        "            if a[i-1] == b[j-1]:\n",
        "                dp[i][j] = dp[i-1][j-1] + 1\n",
        "                if dp[i][j] > length:\n",
        "                    length, end = dp[i][j], i\n",
        "    return a[end-length:end]\n",
        "\n",
        "# --- Load filenames and apply filters ---\n",
        "with open(file_path) as f:\n",
        "    filenames = [line.strip() for line in f if line.strip()]\n",
        "\n",
        "# Filter out unwanted extensions and patterns\n",
        "filtered_filenames = [\n",
        "    f for f in filenames\n",
        "    if os.path.splitext(f)[1].lower() not in SKIP_EXTENSIONS\n",
        "    and not any(pat in f for pat in SKIP_PATTERNS)\n",
        "]\n",
        "\n",
        "# --- Group filenames by fuzzy similarity ---\n",
        "groups = []\n",
        "used = set()\n",
        "\n",
        "for i, f1 in enumerate(filtered_filenames):\n",
        "    if f1 in used:\n",
        "        continue\n",
        "    used.add(f1)\n",
        "    group = [f1]\n",
        "    for f2 in filtered_filenames[i+1:]:\n",
        "        if f2 in used:\n",
        "            continue\n",
        "        if fuzz.ratio(f1, f2) >= SIMILARITY_THRESHOLD:\n",
        "            group.append(f2)\n",
        "            used.add(f2)\n",
        "    if len(group) >= MIN_CLUSTER_SIZE:\n",
        "        groups.append(group)\n",
        "\n",
        "# --- Print clusters with longest common substring ---\n",
        "for idx, g in enumerate(groups, 1):\n",
        "    lcs = g[0]\n",
        "    for f in g[1:]:\n",
        "        lcs = longest_common_substring(lcs, f)\n",
        "    print(f\"Cluster {idx} (LCS: '{lcs}') â†’ {len(g)} files\")\n",
        "    for f in g:\n",
        "        print(\"   \", f)\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "KbdJ7XfTp0bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "output_csv = \"/content/drive/My Drive/Data/filename_clusters.csv\"\n",
        "\n",
        "with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    # Header\n",
        "    writer.writerow([\"cluster_index\", \"lcs\", \"num_files\", \"file_list\"])\n",
        "\n",
        "    for idx, g in enumerate(groups, 1):\n",
        "        lcs = g[0]\n",
        "        for f in g[1:]:\n",
        "            lcs = longest_common_substring(lcs, f)\n",
        "        writer.writerow([idx, lcs, len(g), \"; \".join(g)])\n",
        "\n",
        "print(f\"Clusters exported to '{output_csv}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWG90ptesQnN",
        "outputId": "646f31cf-f70e-4bea-c64f-d01eff629473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clusters exported to '/content/drive/My Drive/Data/filename_clusters.csv'\n"
          ]
        }
      ]
    }
  ]
}